#include "Audio.h"
#include <cassert>
#include <mfapi.h>
#include <mfidl.h>

Audio* Audio::GetInstance() {
	static Audio instance;

	return &instance;
}

void Audio::Initialize() {
	//HRESULT result;
	//// Xaudio2エンジンのインスタンスを生成
	//result = XAudio2Create(&xAudio2_, 0, XAUDIO2_DEFAULT_PROCESSOR);
	//// マスターボイスを生成
	//result = xAudio2_->CreateMasteringVoice(&masterVoice_);
}

SoundData Audio::SoundLoadWave(const char* filename) {
	// .wavファイルを開く
	std::ifstream file;
	// .wavファイルをバイナリモードで開く
	file.open(filename, std::ios_base::binary);
	// ファイルオープン失敗を検出する
	assert(file.is_open());

	// .wavデータ読み込み
	// RIFFヘッダの読み込み
	RiffHeader riff;
	file.read((char*)&riff, sizeof(riff));
	// ファイルはRIFF?
	if (strncmp(riff.chunk.id, "RIFF", 4) != 0) {
		assert(0);
	}
	// タイプはWAVE?
	if (strncmp(riff.type, "WAVE", 4) != 0) {
		assert(0);
	}
	// Formatチャンクの読み込み
	FormatChunk format = {};
	// チャンクの読み込み
	file.read((char*)&format, sizeof(ChunkHeader));
	if (strncmp(format.chunk.id, "fmt ", 4) != 0) {
		assert(0);
	}

	// チャンク本体の読み込み
	assert(format.chunk.size <= sizeof(format.fmt));
	file.read((char*)&format.fmt, format.chunk.size);
	// Dataチャンクの読み込み
	ChunkHeader data;
	file.read((char*)&data, sizeof(data));
	// JUNKチャンクを検出した場合
	if (strncmp(data.id, "JUNK", 4) == 0) {
		// 読み取り位置をJUNKチャンクの終わりまで進める
		file.seekg(data.size, std::ios_base::cur);
		// 再読み込み
		file.read((char*)&data, sizeof(data));
	}

	if (strncmp(data.id, "data", 4) != 0) {
		assert(0);
	}

	// Dataチャンクのデータ部(波形データ)の読み込み
	char* pBuffer = new char[data.size];
	file.read(pBuffer, data.size);

	// Waveファイルを閉じる
	file.close();

	// returnするための音声データ
	SoundData soundData = {};
	soundData.wfex = format.fmt;
	soundData.pBuffer = reinterpret_cast<BYTE*>(pBuffer);
	soundData.bufferSize = data.size;

	return soundData;
}

void Audio::SoundUnload(SoundData* soundData) {
	// バッファのメモリを解放
	delete[] soundData->pBuffer;

	soundData->pBuffer = 0;
	soundData->bufferSize = 0;
	soundData->wfex = {};
}

void Audio::SoundPlayWave(IXAudio2* xAudio2, const SoundData& soundData, float volume) {
	HRESULT result;

	//波形フォーマットもとにSourceVoiceの生成
	IXAudio2SourceVoice* pSourceVoice = nullptr;
	result = xAudio2->CreateSourceVoice(&pSourceVoice, &soundData.wfex);
	assert(SUCCEEDED(result));

	// 再生する波形データの設定
	XAUDIO2_BUFFER buf{};
	buf.pAudioData = soundData.pBuffer;
	buf.AudioBytes = soundData.bufferSize;
	buf.Flags = XAUDIO2_END_OF_STREAM;

	// 波形データの再生
	result = pSourceVoice->SubmitSourceBuffer(&buf);
	// 音量の設定
	result = pSourceVoice->SetVolume(volume); // 1.0fが通常の音量
	// 再生開始
	result = pSourceVoice->Start();
}

void Audio::SoundPlayLoopingWave(IXAudio2* xAudio2, const SoundData& soundData, float volume) {
	HRESULT result;

	//波形フォーマットもとにSourceVoiceの生成
	IXAudio2SourceVoice* pSourceVoice = nullptr;
	result = xAudio2->CreateSourceVoice(&pSourceVoice, &soundData.wfex);
	assert(SUCCEEDED(result));

	// 再生する波形データの設定
	XAUDIO2_BUFFER buf{};
	buf.pAudioData = soundData.pBuffer;
	buf.AudioBytes = soundData.bufferSize;
	buf.Flags = XAUDIO2_END_OF_STREAM;
	buf.LoopCount = XAUDIO2_LOOP_INFINITE;

	// 波形データの再生
	result = pSourceVoice->SubmitSourceBuffer(&buf);
	// 音量の設定
	result = pSourceVoice->SetVolume(volume); // 1.0fが通常の音量
	// 再生開始
	result = pSourceVoice->Start();
}
//
//
//HRESULT Audio::InitializeMediaFoundation() {
//	return CoInitializeEx(NULL, COINIT_APARTMENTTHREADED | COINIT_DISABLE_OLE1DDE);
//}
//
//void Audio::ShutdownMediaFoundation() {
//	CoUninitialize();
//}
//
//HRESULT LoadMP3File(const wchar_t* mp3FilePath, IMFSourceReader** sourceReader);
//
//HRESULT ConfigureAudioOutput(IMFSourceReader* sourceReader, const wchar_t* wavFilePath);
//
//HRESULT WriteWavHeader(const wchar_t* wavFilePath, WAVEFORMATEX* pWaveFormat);
//
//HRESULT DecodeAndWriteAudioData(IMFSourceReader* sourceReader, const wchar_t* wavFilePath);
//
//HRESULT UpdateWavFileSize(const wchar_t* wavFilePath);
